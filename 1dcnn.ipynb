{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f31f366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from phmd import datasets\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder, RobustScaler\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.fft import fft\n",
    "from scipy.fft import fft, fftfreq\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dad711b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(X, y, window_size=256, step=50):\n",
    "    X_seq, y_seq = [], []\n",
    "\n",
    "    for i in range(0, len(X) - window_size, step):\n",
    "        X_seq.append(X[i:i+window_size])\n",
    "        y_seq(y[i+window_size])\n",
    "\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "\n",
    "def calculate_r2(preds, targets):\n",
    "    # Convert tensors to numpy for sklearn\n",
    "    preds = preds.cpu().detach().numpy()\n",
    "    targets = targets.cpu().detach().numpy()\n",
    "    return r2_score(targets, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95d37866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remember to cite the original publisher dataset:\n",
      "\t@inproceedings{nectoux2012pronostia,    \n",
      "\t    title={PRONOSTIA: An experimental platform for bearings accelerated degradation tests.},    \n",
      "\t    author={Nectoux, Patrick and Gouriveau, Rafael and Medjaher, Kamal and Ramasso, Emmanuel and Chebel-Morello, Brigitte and Zerhouni, Noureddine and Varnier, Christophe},    \n",
      "\t    booktitle={IEEE International Conference on Prognostics and Health Management, PHM'12.},    \n",
      "\t    pages={1--8},    \n",
      "\t    year={2012},    \n",
      "\t    organization={IEEE Catalog Number: CPF12PHM-CDR}    \n",
      "\t}\n",
      "You can download the dataset manually from:  https://www.nasa.gov/intelligent-systems-division/discovery-and-systems-health/pcoe/pcoe-data-set-repository/\n",
      "\n",
      "** If you find this tool useful, please cite our SoftwareX paper: \n",
      "\tSolís-Martín, David, Juan Galán-Páez, and Joaquín Borrego-Díaz. \"PHMD: An easy data access tool for prognosis and health management datasets.\" SoftwareX 29 (2025): 102039.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading Bearing3_2: 100%|██████████| 7534/7534 [00:22<00:00, 340.67it/s]\n",
      "Reading Bearing3_3: 100%|██████████| 13959/13959 [00:37<00:00, 369.69it/s]\n",
      "INFO:root:Read in 62.68148684501648 seconds\n"
     ]
    }
   ],
   "source": [
    "TRAIN_BEARINGS = {\n",
    "    1: [\n",
    "        '1_1',\n",
    "        '1_2',\n",
    "    ],\n",
    "    2: [\n",
    "        '2_1',\n",
    "        '2_2',\n",
    "    ],\n",
    "    3: [\n",
    "        '3_1',\n",
    "        '3_2',\n",
    "    ]\n",
    "}\n",
    "\n",
    "TEST_BEARINGS = {\n",
    "    1: [\n",
    "        '1_3',\n",
    "        '1_4',\n",
    "        '1_5',\n",
    "        '1_6',\n",
    "        '1_7',\n",
    "    ],\n",
    "    2: [\n",
    "        '2_3',\n",
    "        '2_4',\n",
    "        '2_5',\n",
    "        '2_6',\n",
    "        '2_7',\n",
    "    ],\n",
    "    3: [\n",
    "        '3_3',\n",
    "    ]\n",
    "}\n",
    "\n",
    "dataset = datasets.Dataset('PRONOSTIA')\n",
    "tasks = dataset['rul']\n",
    "df = tasks.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58e5a4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1_1', '1_2', '2_1', '2_2', '3_1', '3_2'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "df[0]['unit'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e59c6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H_acc</th>\n",
       "      <th>rul</th>\n",
       "      <th>unit</th>\n",
       "      <th>V_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.552</td>\n",
       "      <td>28029</td>\n",
       "      <td>1_1</td>\n",
       "      <td>-0.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.501</td>\n",
       "      <td>28029</td>\n",
       "      <td>1_1</td>\n",
       "      <td>-0.480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.138</td>\n",
       "      <td>28029</td>\n",
       "      <td>1_1</td>\n",
       "      <td>0.435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.423</td>\n",
       "      <td>28029</td>\n",
       "      <td>1_1</td>\n",
       "      <td>0.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.802</td>\n",
       "      <td>28029</td>\n",
       "      <td>1_1</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   H_acc    rul unit  V_acc\n",
       "0  0.552  28029  1_1 -0.146\n",
       "1  0.501  28029  1_1 -0.480\n",
       "2  0.138  28029  1_1  0.435\n",
       "3 -0.423  28029  1_1  0.240\n",
       "4 -0.802  28029  1_1  0.020"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36ab7dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1_3', '1_4', '1_5', '1_6', '1_7', '2_3', '2_4', '2_5', '2_6',\n",
       "       '2_7', '3_3'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "df[1]['unit'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b4d16d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          1_1\n",
       "1          1_1\n",
       "2          1_1\n",
       "3          1_1\n",
       "4          1_1\n",
       "          ... \n",
       "2229755    1_2\n",
       "2229756    1_2\n",
       "2229757    1_2\n",
       "2229758    1_2\n",
       "2229759    1_2\n",
       "Name: unit, Length: 9405440, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0][df[0]['unit'].isin(TRAIN_BEARINGS[1])]['unit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b44cdb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vib_h = df[0]['H_acc'].values\n",
    "# vib_v = df[0]['V_acc'].values\n",
    "\n",
    "# Normalize each channel independently\n",
    "# scaler_h = RobustScaler()\n",
    "# scaler_v = RobustScaler()\n",
    "# vib_h_scaled = scaler_h.fit_transform(vib_h.reshape(-1, 1)).flatten()\n",
    "# vib_v_scaled = scaler_v.fit_transform(vib_v.reshape(-1, 1)).flatten()\n",
    "# rul = df[0]['rul']\n",
    "\n",
    "# vib_h_scaled.shape, vib_v_scaled.shape, rul.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6ecf741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H_acc</th>\n",
       "      <th>rul</th>\n",
       "      <th>unit</th>\n",
       "      <th>V_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.552</td>\n",
       "      <td>28029</td>\n",
       "      <td>1_1</td>\n",
       "      <td>-0.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.501</td>\n",
       "      <td>28029</td>\n",
       "      <td>1_1</td>\n",
       "      <td>-0.480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.138</td>\n",
       "      <td>28029</td>\n",
       "      <td>1_1</td>\n",
       "      <td>0.435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.423</td>\n",
       "      <td>28029</td>\n",
       "      <td>1_1</td>\n",
       "      <td>0.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.802</td>\n",
       "      <td>28029</td>\n",
       "      <td>1_1</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229755</th>\n",
       "      <td>-2.595</td>\n",
       "      <td>0</td>\n",
       "      <td>1_2</td>\n",
       "      <td>3.622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229756</th>\n",
       "      <td>-2.869</td>\n",
       "      <td>0</td>\n",
       "      <td>1_2</td>\n",
       "      <td>8.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229757</th>\n",
       "      <td>1.457</td>\n",
       "      <td>0</td>\n",
       "      <td>1_2</td>\n",
       "      <td>8.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229758</th>\n",
       "      <td>1.591</td>\n",
       "      <td>0</td>\n",
       "      <td>1_2</td>\n",
       "      <td>1.403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229759</th>\n",
       "      <td>-4.701</td>\n",
       "      <td>0</td>\n",
       "      <td>1_2</td>\n",
       "      <td>-0.508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9405440 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         H_acc    rul unit  V_acc\n",
       "0        0.552  28029  1_1 -0.146\n",
       "1        0.501  28029  1_1 -0.480\n",
       "2        0.138  28029  1_1  0.435\n",
       "3       -0.423  28029  1_1  0.240\n",
       "4       -0.802  28029  1_1  0.020\n",
       "...        ...    ...  ...    ...\n",
       "2229755 -2.595      0  1_2  3.622\n",
       "2229756 -2.869      0  1_2  8.675\n",
       "2229757  1.457      0  1_2  8.111\n",
       "2229758  1.591      0  1_2  1.403\n",
       "2229759 -4.701      0  1_2 -0.508\n",
       "\n",
       "[9405440 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0][df[0]['unit'].isin(TRAIN_BEARINGS[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2dafbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BearingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, window_size=512, step=64):\n",
    "        self.windows = []\n",
    "        self.ruls = []\n",
    "        \n",
    "        vib_h = df['H_acc'].values\n",
    "        vib_v = df['V_acc'].values\n",
    "        rul = df['rul'].values\n",
    "        \n",
    "        # Normalize per bearing\n",
    "        vib_h = (vib_h - vib_h.mean()) / (vib_h.std() + 1e-8)\n",
    "        vib_v = (vib_v - vib_v.mean()) / (vib_v.std() + 1e-8)\n",
    "        \n",
    "        # Create sequences\n",
    "        for i in range(0, len(vib_h) - window_size, step):\n",
    "            self.windows.append(np.stack([vib_h[i:i+window_size], \n",
    "                                        vib_v[i:i+window_size]], axis=1))\n",
    "            self.ruls.append(rul[i+window_size])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.windows)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.FloatTensor(self.windows[idx]), torch.FloatTensor([self.ruls[idx]])\n",
    "    \n",
    "dataset = BearingDataset(\n",
    "    df=df[0][df[0]['unit'].isin(TRAIN_BEARINGS[1])],\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27eff63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BearingCNN(\n",
      "  (features): Sequential(\n",
      "    (0): Conv1d(2, 64, kernel_size=(50,), stride=(1,), padding=(24,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv1d(64, 128, kernel_size=(25,), stride=(1,), padding=(12,))\n",
      "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv1d(128, 256, kernel_size=(10,), stride=(1,), padding=(5,))\n",
      "    (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (regressor): Sequential(\n",
      "    (0): Linear(in_features=16384, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class BearingCNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(2, 64, kernel_size=50, padding=24),  # (B, 2, 512) -> (B, 64, 512)\n",
    "            torch.nn.BatchNorm1d(64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool1d(2),  # -> (B, 64, 256)\n",
    "            \n",
    "            torch.nn.Conv1d(64, 128, kernel_size=25, padding=12),\n",
    "            torch.nn.BatchNorm1d(128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool1d(2),  # -> (B, 128, 128)\n",
    "            \n",
    "            torch.nn.Conv1d(128, 256, kernel_size=10, padding=5),\n",
    "            torch.nn.BatchNorm1d(256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool1d(2)   # -> (B, 256, 64)\n",
    "        )\n",
    "        \n",
    "        self.regressor = torch.nn.Sequential(\n",
    "            torch.nn.Linear(256*64, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.3),\n",
    "            torch.nn.Linear(128, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # (B, 512, 2) -> (B, 2, 512)\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        return self.regressor(x).squeeze()\n",
    "\n",
    "model = BearingCNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a7be941",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4593 [00:00<?, ?it/s]/home/stepan/Private/bearing_rul/lib/python3.10/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "100%|█████████▉| 4584/4593 [00:41<00:00, 99.65it/s] /home/stepan/Private/bearing_rul/lib/python3.10/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "100%|██████████| 4593/4593 [00:42<00:00, 109.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss 11997063.6777, Train R² = 0.824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4593 [00:00<?, ?it/s]/home/stepan/Private/bearing_rul/lib/python3.10/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "100%|█████████▉| 4587/4593 [01:41<00:00, 61.56it/s]/home/stepan/Private/bearing_rul/lib/python3.10/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "100%|██████████| 4593/4593 [01:41<00:00, 45.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss 3859313.7764, Train R² = 0.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4593 [00:00<?, ?it/s]/home/stepan/Private/bearing_rul/lib/python3.10/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "100%|█████████▉| 4592/4593 [03:47<00:00, 10.39it/s]/home/stepan/Private/bearing_rul/lib/python3.10/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "100%|██████████| 4593/4593 [03:47<00:00, 20.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss 4339864.7245, Train R² = 0.936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)\n",
    "\n",
    "# Early stopping\n",
    "# best_loss = float('inf')\n",
    "# patience = 10\n",
    "# epochs_no_improve = 0\n",
    "train_r2_history = []\n",
    "\n",
    "for epoch in range(3):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "    epoch_train_preds = []\n",
    "    epoch_train_targets = []\n",
    "\n",
    "    for X_batch, y_batch in tqdm(train_loader):\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch).flatten()\n",
    "\n",
    "        epoch_train_preds.append(y_pred)\n",
    "        epoch_train_targets.append(y_batch)\n",
    "\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_preds = torch.cat(epoch_train_preds)\n",
    "    train_targets = torch.cat(epoch_train_targets)\n",
    "    train_r2 = calculate_r2(train_preds, train_targets)\n",
    "    train_r2_history.append(train_r2)\n",
    "    \n",
    "    # Validation\n",
    "    # model.eval()\n",
    "    # with torch.no_grad():\n",
    "    #     val_pred = model(dataset.X.to(device)).flatten()\n",
    "    #     val_loss = criterion(val_pred, dataset.y.to(device))\n",
    "    \n",
    "    print(f'Epoch {epoch}: Train Loss {train_loss/len(train_loader):.4f}, Train R² = {train_r2:.3f}')\n",
    "    \n",
    "    # Early stopping\n",
    "    # if val_loss < best_loss:\n",
    "    #     best_loss = val_loss\n",
    "    #     epochs_no_improve = 0\n",
    "    #     torch.save(model.state_dict(), 'best_model.pth')\n",
    "    # else:\n",
    "    #     epochs_no_improve += 1\n",
    "    #     if epochs_no_improve == patience:\n",
    "    #         print('Early stopping!')\n",
    "    #         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b068a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bearing_rul",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
